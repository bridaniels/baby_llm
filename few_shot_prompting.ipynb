{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompting Engineering \n",
    "--- \n",
    "### *Prompt Engineering*: process of crafting prompt text for a given model/parameters to enable the model to append to your prompt or continue your prompt. \n",
    "- Includes instructions, context, examples, and cue. <sup>[1](https://www.ibm.com/docs/en/watsonx-as-a-service?topic=models-prompt-tips)</sup>\n",
    "    - *instruction*: imperative statement\n",
    "    - *context*: include information to guide model towards desired output \n",
    "    - *examples*: indicate desired format/shape of output via examples \n",
    "    - *que*: text at the end of the prompt likely to start the generated output on a desired path \n",
    "- technique to enable in-context learning where we provide demonstrations in the prompt to steer the model to better performance <sup>[2](https://www.promptingguide.ai/techniques/fewshot)</sup>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Zero-Shot Learning*\n",
    "---\n",
    "### model learns how to classify classes it has not seen before <sup>[4](https://towardsdatascience.com/understanding-zero-shot-learning-making-ml-more-human-4653ac35ccab)</sup>\n",
    "- give model a prompt that is a natural language instruction describing the task <sup>[7](https://arxiv.org/pdf/2005.14165.pdf)</sup>\n",
    "- give model a prompt that is not part of the training data, and the model can create desired output \n",
    "    - *CAPTCHA image identification*\n",
    "- machine learning models would have to be fundamentally adapted before adding new classes/changing the output criteria, while large language models do not have to be retrained <sup>[3](https://machinelearningmastery.com/what-are-zero-shot-prompting-and-few-shot-prompting/)</sup>\n",
    "\n",
    "> ### Contrastive Language-Image Pretraining (CLIP)\n",
    "> - Goal: *Classify Images Without Any Explicit Labels*\n",
    "> - Two Stages: training stage and inference stage (same as supervised models)\n",
    ">   - *training stage*:  CLIP learns about images via corresponding auxiliary text \n",
    ">       - auxillary text is a form of supervision via data attributes, not labels (computationally expensive)<sup>[5](https://arxiv.org/pdf/2106.02869.pdf)</sup>\n",
    ">       - over time the model learns to extract more important information resulting in better output \n",
    ">   - *inference stage*: minimize difference between image encoding and corresponding text \n",
    ">       - encodings: lower-dimension representations of data, aka the most important/distinguishable information \n",
    ">       - model output = encodings of trained images   \n",
    ">       - expected output = text encoding of corresponding captions \n",
    ">\n",
    "> - *Contrastive Learning*: ML technique used to learn dataset features without labels <sup>[6](https://towardsdatascience.com/understanding-contrastive-learning-d5b19fd96607)</sup>\n",
    ">   - model learns correlation of various data points \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *Few-Shot Prompting*\n",
    "---\n",
    "### *Few-Shot Prompting*: provide examples when you are unable to properly articulate input for desired output but still want results\n",
    "- no instructions necessary, the examples show the model how you expect it to respond\n",
    "- works by giving *K* examples of context/completion \n",
    "    - and one final example of context where which the model is expected to provide completion \n",
    "- learning based on a broad distribution of tasks and then rapidly adapting to a new task <sup>[7](https://arxiv.org/pdf/2005.14165.pdf)</sup>\n",
    "- random nature of the model = potentially different output each time <sup>[3](https://machinelearningmastery.com/what-are-zero-shot-prompting-and-few-shot-prompting/)</sup>\n",
    "\n",
    "> Advantages: <sup>[7](https://arxiv.org/pdf/2005.14165.pdf)</sup>\n",
    "> - reduction of task-specific data needed\n",
    "> - reduced potential to learn a narrow distribution from a large but narrow fine-tuning dataset \n",
    ">\n",
    "> Disadvantages: <sup>[7](https://arxiv.org/pdf/2005.14165.pdf)</sup>\n",
    "> - results are worse than fine-tuned-models\n",
    "> - small amount of task specific data still required \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# Code Time! \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few-Shot Prompt Templates: \n",
    "---\n",
    "### Import Libraries\n",
    "---\n",
    "[langchain documentation for few-shot prompts](https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/few_shot_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example set\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "#example selector\n",
    "from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "key_xyz = \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *K* Examples for Few-Shot Prompting\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "  {\n",
    "    \"question\": \"Who lived longer, Muhammad Ali or Alan Turing?\",\n",
    "    \"answer\": \n",
    "\"\"\"\n",
    "Are follow up questions needed here: Yes.\n",
    "Follow up: How old was Muhammad Ali when he died?\n",
    "Intermediate answer: Muhammad Ali was 74 years old when he died.\n",
    "Follow up: How old was Alan Turing when he died?\n",
    "Intermediate answer: Alan Turing was 41 years old when he died.\n",
    "So the final answer is: Muhammad Ali\n",
    "\"\"\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"When was the founder of craigslist born?\",\n",
    "    \"answer\": \n",
    "\"\"\"\n",
    "Are follow up questions needed here: Yes.\n",
    "Follow up: Who was the founder of craigslist?\n",
    "Intermediate answer: Craigslist was founded by Craig Newmark.\n",
    "Follow up: When was Craig Newmark born?\n",
    "Intermediate answer: Craig Newmark was born on December 6, 1952.\n",
    "So the final answer is: December 6, 1952\n",
    "\"\"\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"Who was the maternal grandfather of George Washington?\",\n",
    "    \"answer\":\n",
    "\"\"\"\n",
    "Are follow up questions needed here: Yes.\n",
    "Follow up: Who was the mother of George Washington?\n",
    "Intermediate answer: The mother of George Washington was Mary Ball Washington.\n",
    "Follow up: Who was the father of Mary Ball Washington?\n",
    "Intermediate answer: The father of Mary Ball Washington was Joseph Ball.\n",
    "So the final answer is: Joseph Ball\n",
    "\"\"\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"Are both the directors of Jaws and Casino Royale from the same country?\",\n",
    "    \"answer\":\n",
    "\"\"\"\n",
    "Are follow up questions needed here: Yes.\n",
    "Follow up: Who is the director of Jaws?\n",
    "Intermediate Answer: The director of Jaws is Steven Spielberg.\n",
    "Follow up: Where is Steven Spielberg from?\n",
    "Intermediate Answer: The United States.\n",
    "Follow up: Who is the director of Casino Royale?\n",
    "Intermediate Answer: The director of Casino Royale is Martin Campbell.\n",
    "Follow up: Where is Martin Campbell from?\n",
    "Intermediate Answer: New Zealand.\n",
    "So the final answer is: No\n",
    "\"\"\"\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Formatting \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who lived longer, Muhammad Ali or Alan Turing?\n",
      "\n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: How old was Muhammad Ali when he died?\n",
      "Intermediate answer: Muhammad Ali was 74 years old when he died.\n",
      "Follow up: How old was Alan Turing when he died?\n",
      "Intermediate answer: Alan Turing was 41 years old when he died.\n",
      "So the final answer is: Muhammad Ali\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pull First Example From Dictionary To Define Formatting\n",
    "\n",
    "example_prompt = PromptTemplate(input_variables=[\"question\",\"answer\"], template=\"Question: {question}\\n{answer}\")\n",
    "print(example_prompt.format(**examples[0]))\n",
    "#print(examples[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create `FewShotPromptTemplate` Object \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who lived longer, Muhammad Ali or Alan Turing?\n",
      "\n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: How old was Muhammad Ali when he died?\n",
      "Intermediate answer: Muhammad Ali was 74 years old when he died.\n",
      "Follow up: How old was Alan Turing when he died?\n",
      "Intermediate answer: Alan Turing was 41 years old when he died.\n",
      "So the final answer is: Muhammad Ali\n",
      "\n",
      "\n",
      "Question: When was the founder of craigslist born?\n",
      "\n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: Who was the founder of craigslist?\n",
      "Intermediate answer: Craigslist was founded by Craig Newmark.\n",
      "Follow up: When was Craig Newmark born?\n",
      "Intermediate answer: Craig Newmark was born on December 6, 1952.\n",
      "So the final answer is: December 6, 1952\n",
      "\n",
      "\n",
      "Question: Who was the maternal grandfather of George Washington?\n",
      "\n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: Who was the mother of George Washington?\n",
      "Intermediate answer: The mother of George Washington was Mary Ball Washington.\n",
      "Follow up: Who was the father of Mary Ball Washington?\n",
      "Intermediate answer: The father of Mary Ball Washington was Joseph Ball.\n",
      "So the final answer is: Joseph Ball\n",
      "\n",
      "\n",
      "Question: Are both the directors of Jaws and Casino Royale from the same country?\n",
      "\n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: Who is the director of Jaws?\n",
      "Intermediate Answer: The director of Jaws is Steven Spielberg.\n",
      "Follow up: Where is Steven Spielberg from?\n",
      "Intermediate Answer: The United States.\n",
      "Follow up: Who is the director of Casino Royale?\n",
      "Intermediate Answer: The director of Casino Royale is Martin Campbell.\n",
      "Follow up: Where is Martin Campbell from?\n",
      "Intermediate Answer: New Zealand.\n",
      "So the final answer is: No\n",
      "\n",
      "\n",
      "Question: When was the founder of craigslist born?\n"
     ]
    }
   ],
   "source": [
    "# Create FewShotPromptTemplate Object: takes in examples + formatter as input \n",
    "\n",
    "prompt = FewShotPromptTemplate(\n",
    "    examples = examples, \n",
    "    example_prompt = example_prompt, \n",
    "    suffix = \"Question: {input}\", \n",
    "    input_variables=[\"input\"]\n",
    ")\n",
    "#print(prompt.format(input=\"Who was the father of Mary Ball Washington?\"))\n",
    "print(prompt.format(input=\"When was the founder of craigslist born?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed Examples into `ExampleSelector`\n",
    "---\n",
    " - reuse example set and formatter from previous \n",
    " - feed examples into `ExampleSelector` vs. `FewShotPromptTemplate`\n",
    " - `SemanticSimilarityExampleSelector` class to select few-shot examples based on similarity to input\n",
    "    - uses embedding model to compute similarity between input and examples\n",
    "    - also uses vector store to perform nearest neightbor search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples Most Similar To Input: Who was the father of Mary Ball Washington?\n",
      "\n",
      "\n",
      "question: Who was the maternal grandfather of George Washington?\n",
      "answer: \n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: Who was the mother of George Washington?\n",
      "Intermediate answer: The mother of George Washington was Mary Ball Washington.\n",
      "Follow up: Who was the father of Mary Ball Washington?\n",
      "Intermediate answer: The father of Mary Ball Washington was Joseph Ball.\n",
      "So the final answer is: Joseph Ball\n",
      "\n"
     ]
    }
   ],
   "source": [
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    examples, #List of Examples to Choose From \n",
    "    OpenAIEmbeddings(openai_api_key=key_xyz), #Embedding Class Used to Produce Embeddings Measring Semantic Similarity \n",
    "    Chroma, #VectorStore Class Used to Store Embeddings + Do Similarity Search\n",
    "    k=1 #Output to Produce\n",
    ")\n",
    "\n",
    "question = \"Who was the father of Mary Ball Washington?\"\n",
    "selected_ex = example_selector.select_examples({\"question\": question})\n",
    "\n",
    "print(f\"Examples Most Similar To Input: {question}\")\n",
    "for example in selected_ex:\n",
    "    print(\"\\n\")\n",
    "    for k, v in reversed(example.items()): \n",
    "    # for k, v in example.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "\n",
    "#\"answer\" is first key in dictionary instead of \"question\" - no clue why \n",
    "# print(selected_ex[0].keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed `ExampleSelector` into `FewShotPromptTemplate` Object\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who was the maternal grandfather of George Washington?\n",
      "\n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: Who was the mother of George Washington?\n",
      "Intermediate answer: The mother of George Washington was Mary Ball Washington.\n",
      "Follow up: Who was the father of Mary Ball Washington?\n",
      "Intermediate answer: The father of Mary Ball Washington was Joseph Ball.\n",
      "So the final answer is: Joseph Ball\n",
      "\n",
      "\n",
      "Question: Who was the father of Mary Ball Washington?\n"
     ]
    }
   ],
   "source": [
    "prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector, \n",
    "    example_prompt= example_prompt, \n",
    "    suffix=\"Question: {input}\", \n",
    "    input_variables=[\"input\"]\n",
    ")\n",
    "\n",
    "print(prompt.format(input=\"Who was the father of Mary Ball Washington?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few-Shot Examples: Chat Models \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References: \n",
    "1.  [IBM Watson Docs](https://www.ibm.com/docs/en/watsonx-as-a-service?topic=models-prompt-tips)\n",
    "2.  [Prompt Guide AI](https://www.promptingguide.ai/techniques/fewshot)\n",
    "3.  [MLM: What Are Zero-Shot Prompting and Few-Shot Prompting](https://machinelearningmastery.com/what-are-zero-shot-prompting-and-few-shot-prompting/)\n",
    "4.  [TDS: Understanding Zero-Shot Learning Making ML More Human](https://towardsdatascience.com/understanding-zero-shot-learning-making-ml-more-human-4653ac35ccab)\n",
    "5. [Integrading Auxiliary Information in Self-Supervised Learning](https://arxiv.org/pdf/2106.02869.pdf)\n",
    "6. [TDS: Understanding Contrastive Learning](https://towardsdatascience.com/understanding-contrastive-learning-d5b19fd96607)\n",
    "7. [Language Models are Few-Shot Learners](https://arxiv.org/pdf/2005.14165.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
