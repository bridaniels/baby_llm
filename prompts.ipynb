{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langchain Prompts: \n",
    "--- \n",
    "([documentation](https://python.langchain.com/docs/modules/model_io/prompts))\n",
    " - set of instructions/input provided by a user to guide the model's output "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries + Setup API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prompt Template\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "#Chat Prompt Template\n",
    "from langchain.prompts import ChatPromptTemplate \n",
    "from langchain.prompts.chat import SystemMessage, HumanMessagePromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "key_xyz = \"sk-\"\n",
    "\n",
    "# llm = OpenAI(openai_api_key=key_xyz)\n",
    "chat_model=ChatOpenAI(openai_api_key=key_xyz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Template: \n",
    "--- \n",
    "- `PromptTemplate` uses string format for input *(however, other formats are workable)*\n",
    "    - can use as many variables as you want or no variables\n",
    "    - `input_variables` will be compared against variables present in the template string\n",
    "        - exception raised if there is a mismatch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a funny joke about chickens.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PromptTemplate: 2 Variables \n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"Tell me a {adjective} joke about {content}.\"\n",
    "    )\n",
    "prompt_template.format(adjective=\"funny\", content=\"chickens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me a joke'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PromptTemplate: 0 Variables \n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"Tell me a joke\"\n",
    "    )\n",
    "prompt_template.format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell me a funny joke about chickens\n"
     ]
    }
   ],
   "source": [
    "# PromptTemplate: input_variables \n",
    "\n",
    "valid_prompt = PromptTemplate(\n",
    "    input_variables=[\"adjective\", \"content\"],\n",
    "    template=\"Tell me a {adjective} joke about {content}\"\n",
    "    )\n",
    "print(valid_prompt.format(adjective=\"funny\",content=\"chickens\"))\n",
    "\n",
    "# EXCEPTION RAISED: two variables but only one defined input_variable\n",
    "# invalid_prompt = PromptTemplate(\n",
    "#     input_variables = [\"adjective\"], \n",
    "#     template=\"Tell me a {adjective} joke about {content}.\"\n",
    "#     )\n",
    "# invalid_prompt.format(adjective=\"funny\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chat Prompt Template:\n",
    "---\n",
    "- chat messages associated with a `role` and `content` parameters \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful AI bot. Your name is Bob.\n",
      "Hello, how are you doing?\n",
      "I'm doing well, thanks!\n",
      "What is your name?\n"
     ]
    }
   ],
   "source": [
    "# 2-tuple representation of (type, content)\n",
    "\n",
    "template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful AI bot. Your name is {name}.\"), \n",
    "    (\"human\", \"Hello, how are you doing?\"),\n",
    "    (\"ai\", \"I'm doing well, thanks!\"), \n",
    "    (\"human\", \"{user_input}\")\n",
    "    ])\n",
    "messages = template.format_messages(\n",
    "    name = \"Bob\", \n",
    "    user_input = \"What is your name?\"\n",
    "    )\n",
    "\n",
    "# messages\n",
    "for x in range(len(messages)): \n",
    "    print(messages[x].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content Output: \n",
      " I absolutely love indulging in delicious treats! \n",
      "ChatMessage Output:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='I absolutely love indulging in delicious treats!', additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pass instance of `MessagePromptTemplate` or `BaseMessage`\n",
    "\n",
    "template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessage(content=(\"You are a helpful assistant that re-writes the user's text to sound more upbeat.\")),\n",
    "        HumanMessagePromptTemplate.from_template(\"{text}\"),\n",
    "    ]\n",
    ")\n",
    "upbeat = chat_model(template.format_messages(text=\"I don't like eating tasty things.\"))\n",
    "\n",
    "print(\"Content Output: \\n {} \\nChatMessage Output:\".format(upbeat.content))\n",
    "upbeat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Prompt Template\n",
    "## **METACLASS ERRORS**\n",
    "--- \n",
    "([description](https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/custom_prompt_template.html))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Langchain provides set of default prompt templates, do not meet all needs \n",
    "- Two Prompt Templates Avaliable: \n",
    "    - String Prompt Template: simple prompt in string format \n",
    "        - Requirements: `input_variables` attribute and defined format method for keyword arguments corresponding to expected `input_variables` and returns the formatted prompt \n",
    "    - Chat Prompt Template: produces a more structured prompt to be used with chat API "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [metaclass conflict github chat](https://github.com/langchain-ai/langchain/issues/9702)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import inspect \n",
    "\n",
    "# from langchain.prompts import StringPromptTemplate\n",
    "# from pydantic import BaseModel, Field, validator \n",
    "\n",
    "\n",
    "# #from pydantic.main import ModelMetaclass\n",
    "# #Error\n",
    "\n",
    "# import metaclass_error \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Return Source Code Of A Function Given It's Name \n",
    "\n",
    "# def get_source_code(function_name): \n",
    "#     return inspect.getsource(function_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # def partial(self, **kwargs: Union[str, Callable[[], str]]) -> BasePromptTemplate: \n",
    "    #     \"\"\"Return a partial of the prompt template\"\"\"\n",
    "    #     prompt_dict = self.__dict__.copy()\n",
    "    #     prompt_dict[\"input_variables\"] = list(\n",
    "    #         set(self.input_variables).difference(kwargs)\n",
    "    #     )\n",
    "    #     prompt_dict[\"partial_variables\"] = {**self.partial_variables, **kwargs}\n",
    "    #     return type(self)(**prompt_dict) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import inspect\n",
    "# import types\n",
    "# import builtins  \n",
    "\n",
    "# def skip_redundant(iterable, skipset=None):\n",
    "#     if skipset is None:\n",
    "#         skipset = set()\n",
    "#     for item in iterable:\n",
    "#         if item not in skipset:\n",
    "#             skipset.add(item)\n",
    "#             yield item\n",
    "\n",
    "# def remove_redundant(metaclasses):\n",
    "#     skipset = set([types.ClassType])\n",
    "#     for meta in metaclasses:\n",
    "#         skipset.update(inspect.getmro(meta)[1:])\n",
    "#     return tuple(skip_redundant(metaclasses, skipset))\n",
    "\n",
    "# memoized_metaclasses_map = {}\n",
    "\n",
    "# def get_noconflict_metaclass(bases, left_metas, right_metas):\n",
    "\n",
    "#     metas = left_metas + tuple(map(type, bases)) + right_metas\n",
    "#     needed_metas = remove_redundant(metas)\n",
    "\n",
    "#     if needed_metas in memoized_metaclasses_map:\n",
    "#         return memoized_metaclasses_map[needed_metas]\n",
    "#     elif not needed_metas:\n",
    "#         meta = type\n",
    "#     elif len(needed_metas) == 1:\n",
    "#         meta = needed_metas[0]\n",
    "#     elif needed_metas == bases:\n",
    "#         raise TypeError(\"Incompatible root metatypes\", needed_metas)\n",
    "#     else:  # gotta work ...\n",
    "#         metaname = '_' + ''.join([m.__name__ for m in needed_metas])\n",
    "#         meta = classmaker()(metaname, needed_metas, {})\n",
    "#     memoized_metaclasses_map[needed_metas] = meta\n",
    "#     return meta\n",
    "\n",
    "# def classmaker(left_metas=(), right_metas=()):\n",
    "#     def make_class(name, bases, adict):\n",
    "#         metaclass = get_noconflict_metaclass(bases, left_metas, right_metas)\n",
    "#         return metaclass(name, bases, adict)\n",
    "#     return make_class\n",
    "\n",
    "# class your_class(Chain, BaseModel): \n",
    "#     __metaclass__=classmaker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom String Prompt Template \n",
    "\n",
    "# PROMPT = \"\"\"\\\n",
    "#     Given the function name and source code, generate an English languag explanation of the function. \n",
    "#     Function Name: {function_name}\n",
    "#     Source Code: {source_code}\n",
    "#     Explanation: \n",
    "#     \"\"\"\n",
    "\n",
    "# *Metaclass Conflicts*\n",
    "\n",
    "# class CombinedMeta(type(BasePromptTemplate), ModelMetaclass): \n",
    "#     pass\n",
    "# class FunctionExplainerPromptTemplate(StringPromptTemplate, BaseModel, metaclass=CombinedMeta):\n",
    "    \n",
    "# class FunctionExplainerPromptTemplate(StringPromptTemplate, BaseModel):     \n",
    "#     \"\"\"A custom prompt template that takes in the function name as input,\n",
    "#     formats the prompt template to provide the source code of the function\"\"\"\n",
    "#     input_variables: list = Field(..., description=\"The input variables for the prompt template\")\n",
    "    \n",
    "#     def partial(self, **kwargs: Union[str, Callable[[], str]]) -> BasePromptTemplate: \n",
    "#         \"\"\"Return a partial of the prompt template\"\"\"\n",
    "#         prompt_dict = self.__dict__.copy()\n",
    "#         prompt_dict[\"input_variables\"] = list(\n",
    "#             set(self.input_variables).difference(kwargs)\n",
    "#         )\n",
    "#         prompt_dict[\"partial_variables\"] = {**self.partial_variables, **kwargs}\n",
    "#         return type(self)(**prompt_dict) \n",
    "\n",
    "#     @validator(\"input_variables\") \n",
    "#     def validate_input_variables(cls, v): \n",
    "#         if len(v) !=1 or \"function_name\" not in v: \n",
    "#             raise ValueError(\"function_name must be the only input_variable\")\n",
    "#         return v \n",
    "\n",
    "#     def format(self, **kwargs) -> str: \n",
    "#         source_code = get_source_code(kwards[\"function_name\"])\n",
    "#         prompt = PROMPT.format(\n",
    "#             function_name=kwargs[\"function_name\"].__name__, source_code=source_code\n",
    "#         )\n",
    "#         return prompt \n",
    "\n",
    "#     def _prompt_type(self): \n",
    "#         return \"function-explainer\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few-Shot Prompt Templates: \n",
    "---\n",
    "- template constructed from a set of examples or an examplet selector object \n",
    "- examples: dictionary with keys being input variables and values being for the input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example set\n",
    "from langchain.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "#example selector\n",
    "from langchain.prompts.example_selector import SemanticSimilarityExampleSelector\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "  {\n",
    "    \"question\": \"Who lived longer, Muhammad Ali or Alan Turing?\",\n",
    "    \"answer\": \n",
    "\"\"\"\n",
    "Are follow up questions needed here: Yes.\n",
    "Follow up: How old was Muhammad Ali when he died?\n",
    "Intermediate answer: Muhammad Ali was 74 years old when he died.\n",
    "Follow up: How old was Alan Turing when he died?\n",
    "Intermediate answer: Alan Turing was 41 years old when he died.\n",
    "So the final answer is: Muhammad Ali\n",
    "\"\"\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"When was the founder of craigslist born?\",\n",
    "    \"answer\": \n",
    "\"\"\"\n",
    "Are follow up questions needed here: Yes.\n",
    "Follow up: Who was the founder of craigslist?\n",
    "Intermediate answer: Craigslist was founded by Craig Newmark.\n",
    "Follow up: When was Craig Newmark born?\n",
    "Intermediate answer: Craig Newmark was born on December 6, 1952.\n",
    "So the final answer is: December 6, 1952\n",
    "\"\"\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"Who was the maternal grandfather of George Washington?\",\n",
    "    \"answer\":\n",
    "\"\"\"\n",
    "Are follow up questions needed here: Yes.\n",
    "Follow up: Who was the mother of George Washington?\n",
    "Intermediate answer: The mother of George Washington was Mary Ball Washington.\n",
    "Follow up: Who was the father of Mary Ball Washington?\n",
    "Intermediate answer: The father of Mary Ball Washington was Joseph Ball.\n",
    "So the final answer is: Joseph Ball\n",
    "\"\"\"\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"Are both the directors of Jaws and Casino Royale from the same country?\",\n",
    "    \"answer\":\n",
    "\"\"\"\n",
    "Are follow up questions needed here: Yes.\n",
    "Follow up: Who is the director of Jaws?\n",
    "Intermediate Answer: The director of Jaws is Steven Spielberg.\n",
    "Follow up: Where is Steven Spielberg from?\n",
    "Intermediate Answer: The United States.\n",
    "Follow up: Who is the director of Casino Royale?\n",
    "Intermediate Answer: The director of Casino Royale is Martin Campbell.\n",
    "Follow up: Where is Martin Campbell from?\n",
    "Intermediate Answer: New Zealand.\n",
    "So the final answer is: No\n",
    "\"\"\"\n",
    "  }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who lived longer, Muhammad Ali or Alan Turing?\n",
      "\n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: How old was Muhammad Ali when he died?\n",
      "Intermediate answer: Muhammad Ali was 74 years old when he died.\n",
      "Follow up: How old was Alan Turing when he died?\n",
      "Intermediate answer: Alan Turing was 41 years old when he died.\n",
      "So the final answer is: Muhammad Ali\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pull First Example In Dictionary \n",
    "\n",
    "example_prompt = PromptTemplate(input_variables=[\"question\",\"answer\"], template=\"Question: {question}\\n{answer}\")\n",
    "print(example_prompt.format(**examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Who lived longer, Muhammad Ali or Alan Turing?\n",
      "\n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: How old was Muhammad Ali when he died?\n",
      "Intermediate answer: Muhammad Ali was 74 years old when he died.\n",
      "Follow up: How old was Alan Turing when he died?\n",
      "Intermediate answer: Alan Turing was 41 years old when he died.\n",
      "So the final answer is: Muhammad Ali\n",
      "\n",
      "\n",
      "Question: When was the founder of craigslist born?\n",
      "\n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: Who was the founder of craigslist?\n",
      "Intermediate answer: Craigslist was founded by Craig Newmark.\n",
      "Follow up: When was Craig Newmark born?\n",
      "Intermediate answer: Craig Newmark was born on December 6, 1952.\n",
      "So the final answer is: December 6, 1952\n",
      "\n",
      "\n",
      "Question: Who was the maternal grandfather of George Washington?\n",
      "\n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: Who was the mother of George Washington?\n",
      "Intermediate answer: The mother of George Washington was Mary Ball Washington.\n",
      "Follow up: Who was the father of Mary Ball Washington?\n",
      "Intermediate answer: The father of Mary Ball Washington was Joseph Ball.\n",
      "So the final answer is: Joseph Ball\n",
      "\n",
      "\n",
      "Question: Are both the directors of Jaws and Casino Royale from the same country?\n",
      "\n",
      "Are follow up questions needed here: Yes.\n",
      "Follow up: Who is the director of Jaws?\n",
      "Intermediate Answer: The director of Jaws is Steven Spielberg.\n",
      "Follow up: Where is Steven Spielberg from?\n",
      "Intermediate Answer: The United States.\n",
      "Follow up: Who is the director of Casino Royale?\n",
      "Intermediate Answer: The director of Casino Royale is Martin Campbell.\n",
      "Follow up: Where is Martin Campbell from?\n",
      "Intermediate Answer: New Zealand.\n",
      "So the final answer is: No\n",
      "\n",
      "\n",
      "Question: When was the founder of craigslist born?\n"
     ]
    }
   ],
   "source": [
    "prompt = FewShotPromptTemplate(\n",
    "    examples = examples, \n",
    "    example_prompt = example_prompt, \n",
    "    suffix = \"Question: {input}\", \n",
    "    input_variables=[\"input\"]\n",
    ")\n",
    "#print(prompt.format(input=\"Who was the father of Mary Ball Washington?\"))\n",
    "print(prompt.format(input=\"When was the founder of craigslist born?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `ExampleSelector`\n",
    " - reuse example set and formatter from previous \n",
    " - feed examples into `ExampleSelector` vs. `FewShotPromptTemplate`\n",
    " - `SemanticSimilarityExampleSelector` class to select few-shot examples based on similarity to input\n",
    "    - uses embedding model to compute similarity between input and examples\n",
    "    - also uses vector store to perform nearest neightbor search "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
