{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Large Language Models (LLMS)**\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Import Libraries*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup OpenAI API Key \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_xyz = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LLM: takes string as input and returns and string \n",
    "#ChatModels: takes a list of messages as input and returns a message \n",
    "\n",
    "llm = OpenAI(openai_api_key=key_xyz)\n",
    "chat_model = ChatOpenAI(openai_api_key=key_xyz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Work \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "example1 = \"Hello!\"\n",
    "example_sentence = \"What would be a good name for a company that made colorful socks?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example string: Hello! \n",
      " ------ \n",
      " LLM: I'm sorry to hear that you are feeling overwhelmed. It is never easy to feel like you have too much to do and not enough time to do it. Here are some tips that may help:\n",
      "\n",
      "1. Make a to-do list. Writing down your tasks in a list can help you visualize how much you have to do and prioritize what needs to be done first.\n",
      "\n",
      "2. Break down tasks into smaller steps. Sometimes a big task can seem overwhelming, but if you break it down into smaller chunks it can seem more manageable.\n",
      "\n",
      "3. Take a break. Taking a few minutes to relax and breathe can help you regain your focus and clarity.\n",
      "\n",
      "4. Reach out for help. Don't be afraid to ask for help from friends, family, or colleagues if you need it.\n",
      "\n",
      "I hope these tips help you to feel less overwhelmed. Take care! \n",
      " ------ \n",
      " ChatModel: Hi there! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# LLM vs. ChatModel\n",
    "\n",
    "print(\"example string: {} \\n ------ \\n LLM: {} \\n ------ \\n ChatModel: {}\".format(example1,llm.predict(example1)[2:],chat_model.predict(example1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "String Input: [HumanMessage(content='What would be a good name for a company that made colorful socks?', additional_kwargs={}, example=False)] \n",
      " ------ \n",
      " LLM: content='\\n\\nSocktastic!' additional_kwargs={} example=False \n",
      "   Socktastic! \n",
      " ------ \n",
      " ChatModel: content='VibrantSock Co.' additional_kwargs={} example=False \n",
      "   VibrantSock Co.\n"
     ]
    }
   ],
   "source": [
    "messages = [HumanMessage(content=example_sentence)]\n",
    "\n",
    "llm_string1 = llm.predict_messages(messages)\n",
    "cm_string1 = chat_model.predict_messages(messages)\n",
    "\n",
    "print(\"String Input: {} \\n ------ \\n LLM: {} \\n   {} \\n ------ \\n ChatModel: {} \\n   {}\".format(messages, llm_string1, llm_string1.content[2:], cm_string1, cm_string1.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
